{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark \n",
    "from pyspark.sql.functions import col, expr\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import regexp_extract, regexp_replace\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import asc, desc\n",
    "from vega_datasets import data\n",
    "from pyspark.sql.functions import month, year, quarter\n",
    "import pyspark.sql.functions as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a spark data frame that contains your favorite programming languages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Establish spark session \n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Create a spark dataframe \n",
    "languages = spark.sparkContext.parallelize(\n",
    "    [\n",
    "        (1, \"python\"),\n",
    "        (2, \"C++\"),\n",
    "        (3, \"Ruby\"),\n",
    "        (4, \"Julia\"),\n",
    "        (5, \"Java\"),\n",
    "        (6, \"Rust\"),\n",
    "        (7, \"SQL\"),\n",
    "    ]\n",
    ")\n",
    "df = languages.toDF([\"id\", \"language\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|language|\n",
      "+---+--------+\n",
      "|  1|  python|\n",
      "|  2|     C++|\n",
      "|  3|    Ruby|\n",
      "|  4|   Julia|\n",
      "|  5|    Java|\n",
      "|  6|    Rust|\n",
      "|  7|     SQL|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The name of the column should be language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'language'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- View the schema of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('id', LongType(), True), StructField('language', StringType(), True)])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Output the shape of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 2)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Show the first 5 records in the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|language|\n",
      "+--------+\n",
      "|  python|\n",
      "|     C++|\n",
      "|    Ruby|\n",
      "|   Julia|\n",
      "|    Java|\n",
      "+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('language').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the mpg dataset as a spark dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramirolopez/anaconda3/envs/codeup/lib/python3.11/site-packages/pyspark/sql/pandas/conversion.py:485: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if should_localize and is_datetime64tz_dtype(s.dtype) and s.dt.tz is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|Unnamed: 0|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+----------+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|         1|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|         2|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|         3|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|         4|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|         5|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+----------+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg_data = pd.read_csv('mpg.csv')\n",
    "mpg = spark.createDataFrame(mpg_data)\n",
    "mpg.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Create 1 column of output that contains a message like the one below: (For each vehicle.)\n",
    "    - The 1999 audi a4 has a 4 cylinder engine.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order\n",
    "# year\\manufactuer\\model\\string literal\\cyl\\string literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------+\n",
      "|concat(The , year,  , manufacturer,  , model,  has a , cyl,  cylinder engine)|\n",
      "+-----------------------------------------------------------------------------+\n",
      "|The 1999 audi a4 has a 4 cylinder engine                                     |\n",
      "|The 1999 audi a4 has a 4 cylinder engine                                     |\n",
      "|The 2008 audi a4 has a 4 cylinder engine                                     |\n",
      "|The 2008 audi a4 has a 4 cylinder engine                                     |\n",
      "|The 1999 audi a4 has a 6 cylinder engine                                     |\n",
      "|The 1999 audi a4 has a 6 cylinder engine                                     |\n",
      "|The 2008 audi a4 has a 6 cylinder engine                                     |\n",
      "|The 1999 audi a4 quattro has a 4 cylinder engine                             |\n",
      "|The 1999 audi a4 quattro has a 4 cylinder engine                             |\n",
      "|The 2008 audi a4 quattro has a 4 cylinder engine                             |\n",
      "+-----------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(\n",
    "    F.concat(\n",
    "        lit(\"The \"),\n",
    "        mpg.year,\n",
    "        lit(\" \"),\n",
    "        mpg.manufacturer,\n",
    "        lit(\" \"),\n",
    "        mpg.model,\n",
    "        lit(\" has a \"),\n",
    "        mpg.cyl,\n",
    "        lit(\" cylinder engine\"),\n",
    "    )\n",
    ").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----+-----+----+---+--------+---+---+---+---+-------+\n",
      "|Unnamed: 0|manufacturer|model|displ|year|cyl|   trans|drv|cty|hwy| fl|  class|\n",
      "+----------+------------+-----+-----+----+---+--------+---+---+---+---+-------+\n",
      "|         1|        audi|   a4|  1.8|1999|  4|auto(l5)|  f| 18| 29|  p|compact|\n",
      "|         4|        audi|   a4|  2.0|2008|  4|auto(av)|  f| 21| 30|  p|compact|\n",
      "|         5|        audi|   a4|  2.8|1999|  6|auto(l5)|  f| 16| 26|  p|compact|\n",
      "+----------+------------+-----+-----+----+---+--------+---+---+---+---+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.where(mpg[\"trans\"].contains(\"auto\")).show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----+-----+----+---+--------+---+---+---+---+-------+\n",
      "|Unnamed: 0|manufacturer|model|displ|year|cyl|   trans|drv|cty|hwy| fl|  class|\n",
      "+----------+------------+-----+-----+----+---+--------+---+---+---+---+-------+\n",
      "|         1|        audi|   a4|  1.8|1999|  4|auto(l5)|  f| 18| 29|  p|compact|\n",
      "|         4|        audi|   a4|  2.0|2008|  4|auto(av)|  f| 21| 30|  p|compact|\n",
      "|         5|        audi|   a4|  2.8|1999|  6|auto(l5)|  f| 16| 26|  p|compact|\n",
      "+----------+------------+-----+-----+----+---+--------+---+---+---+---+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.where(mpg[\"trans\"].startswith(\"auto\")).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|Unnamed: 0|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+----------+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|         2|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|         3|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|         6|        audi|   a4|  2.8|1999|  6|manual(m5)|  f| 18| 26|  p|compact|\n",
      "+----------+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.where(mpg[\"trans\"].contains(\"manual\")).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "otherwise() can only be applied on a Column previously generated by when()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/ramirolopez/codeup-data-science/spark-exercises/spark101.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ramirolopez/codeup-data-science/spark-exercises/spark101.ipynb#Y150sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mpg\u001b[39m.\u001b[39mwhere(mpg[\u001b[39m\"\u001b[39;49m\u001b[39mtrans\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mcontains(\u001b[39m\"\u001b[39;49m\u001b[39mmanual\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49motherwise(\u001b[39m'\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m'\u001b[39;49m))\u001b[39m.\u001b[39malias(\u001b[39m'\u001b[39m\u001b[39mtranssystem\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/anaconda3/envs/codeup/lib/python3.11/site-packages/pyspark/sql/column.py:1346\u001b[0m, in \u001b[0;36mColumn.otherwise\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   1309\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1310\u001b[0m \u001b[39mEvaluates a list of conditions and returns one of multiple possible result expressions.\u001b[39;00m\n\u001b[1;32m   1311\u001b[0m \u001b[39mIf :func:`Column.otherwise` is not invoked, None is returned for unmatched conditions.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[39mpyspark.sql.functions.when\u001b[39;00m\n\u001b[1;32m   1344\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1345\u001b[0m v \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39m_jc \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, Column) \u001b[39melse\u001b[39;00m value\n\u001b[0;32m-> 1346\u001b[0m jc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jc\u001b[39m.\u001b[39;49motherwise(v)\n\u001b[1;32m   1347\u001b[0m \u001b[39mreturn\u001b[39;00m Column(jc)\n",
      "File \u001b[0;32m~/anaconda3/envs/codeup/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/codeup/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: otherwise() can only be applied on a Column previously generated by when()"
     ]
    }
   ],
   "source": [
    "mpg.where(mpg[\"trans\"].contains(\"manual\").otherwise('auto')).alias('transsystem').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the tips dataset as a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramirolopez/anaconda3/envs/codeup/lib/python3.11/site-packages/pyspark/sql/pandas/conversion.py:485: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if should_localize and is_datetime64tz_dtype(s.dtype) and s.dt.tz is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----+------+------+---+------+----+\n",
      "|Unnamed: 0|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----------+----+------+------+---+------+----+\n",
      "|         1|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|         2|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|         3|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|         4|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|         5|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tip_data = pd.read_csv('tips.csv')\n",
    "tips = spark.createDataFrame(tip_data)\n",
    "tips.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- What percentage of observations are smokers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of smokers -> 38.11\n",
      "Percentage of NON smokers -> 61.89\n"
     ]
    }
   ],
   "source": [
    "count_no = tips.filter(tips.smoker == 'No').count()\n",
    "count_yes = tips.filter(tips.smoker == 'Yes').count()\n",
    "\n",
    "total_population = count_no + count_yes\n",
    "\n",
    "percent_of_smokers = round(count_yes / (total_population) * 100, 2)\n",
    "percent_of_non_smokers = round(count_no / (total_population) * 100, 2)\n",
    "\n",
    "print(f'Percentage of smokers -> {percent_of_smokers}')\n",
    "print(f'Percentage of NON smokers -> {percent_of_non_smokers}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a column that contains the tip percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-------+\n",
      "|customer_tip|total|avg_tip|\n",
      "+------------+-----+-------+\n",
      "|        1.01|16.99|   5.94|\n",
      "|        1.66|10.34|  16.05|\n",
      "|         3.5|21.01|  16.66|\n",
      "|        3.31|23.68|  13.98|\n",
      "|        3.61|24.59|  14.68|\n",
      "+------------+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_column = F.round((col('tip') / col(\"total_bill\")) * 100, 2)\n",
    "\n",
    "tips.select(\n",
    "    col(\"tip\").alias(\"customer_tip\"),\n",
    "    tips.total_bill.alias(\"total\"),\n",
    "    avg_column.alias(\"avg_tip\"),\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the average tip percentage for each combination of sex and smoker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `sex` cannot be resolved. Did you mean one of the following? [`total`, `avg_tip`, `customer_tip`].;\n'Aggregate ['sex, 'smoker], ['sex, 'smoker, avg(round((('tip / 'total_bill) * 100), 2)) AS avg(round(((tip / total_bill) * 100), 2))#3181]\n+- Project [tip#258 AS customer_tip#3171, total_bill#257 AS total#3172, round(((tip#258 / total_bill#257) * cast(100 as double)), 2) AS avg_tip#3173]\n   +- LogicalRDD [Unnamed: 0#256L, total_bill#257, tip#258, sex#259, smoker#260, day#261, time#262, size#263L], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ramirolopez/codeup-data-science/spark-exercises/spark101.ipynb Cell 30\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ramirolopez/codeup-data-science/spark-exercises/spark101.ipynb#Y151sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m avg_column \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mround((col(\u001b[39m'\u001b[39m\u001b[39mtip\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m/\u001b[39m col(\u001b[39m\"\u001b[39m\u001b[39mtotal_bill\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ramirolopez/codeup-data-science/spark-exercises/spark101.ipynb#Y151sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m tips\u001b[39m.\u001b[39;49mselect(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ramirolopez/codeup-data-science/spark-exercises/spark101.ipynb#Y151sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     col(\u001b[39m\"\u001b[39;49m\u001b[39mtip\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49malias(\u001b[39m\"\u001b[39;49m\u001b[39mcustomer_tip\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ramirolopez/codeup-data-science/spark-exercises/spark101.ipynb#Y151sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     tips\u001b[39m.\u001b[39;49mtotal_bill\u001b[39m.\u001b[39;49malias(\u001b[39m\"\u001b[39;49m\u001b[39mtotal\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ramirolopez/codeup-data-science/spark-exercises/spark101.ipynb#Y151sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     avg_column\u001b[39m.\u001b[39;49malias(\u001b[39m\"\u001b[39;49m\u001b[39mavg_tip\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ramirolopez/codeup-data-science/spark-exercises/spark101.ipynb#Y151sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\u001b[39m.\u001b[39;49mgroupBy(\u001b[39m'\u001b[39;49m\u001b[39msex\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39msmoker\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49magg(F\u001b[39m.\u001b[39;49mmean(avg_column))\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/anaconda3/envs/codeup/lib/python3.11/site-packages/pyspark/sql/group.py:186\u001b[0m, in \u001b[0;36mGroupedData.agg\u001b[0;34m(self, *exprs)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(c, Column) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m exprs), \u001b[39m\"\u001b[39m\u001b[39mall exprs should be Column\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m     exprs \u001b[39m=\u001b[39m cast(Tuple[Column, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m], exprs)\n\u001b[0;32m--> 186\u001b[0m     jdf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jgd\u001b[39m.\u001b[39;49magg(exprs[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49m_jc, _to_seq(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49m_sc, [c\u001b[39m.\u001b[39;49m_jc \u001b[39mfor\u001b[39;49;00m c \u001b[39min\u001b[39;49;00m exprs[\u001b[39m1\u001b[39;49m:]]))\n\u001b[1;32m    187\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrame(jdf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession)\n",
      "File \u001b[0;32m~/anaconda3/envs/codeup/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/codeup/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `sex` cannot be resolved. Did you mean one of the following? [`total`, `avg_tip`, `customer_tip`].;\n'Aggregate ['sex, 'smoker], ['sex, 'smoker, avg(round((('tip / 'total_bill) * 100), 2)) AS avg(round(((tip / total_bill) * 100), 2))#3181]\n+- Project [tip#258 AS customer_tip#3171, total_bill#257 AS total#3172, round(((tip#258 / total_bill#257) * cast(100 as double)), 2) AS avg_tip#3173]\n   +- LogicalRDD [Unnamed: 0#256L, total_bill#257, tip#258, sex#259, smoker#260, day#261, time#262, size#263L], false\n"
     ]
    }
   ],
   "source": [
    "avg_column = F.round((col('tip') / col(\"total_bill\")) * 100, 2)\n",
    "\n",
    "tips.select(\n",
    "    col(\"tip\").alias(\"customer_tip\"),\n",
    "    tips.total_bill.alias(\"total\"),\n",
    "    avg_column.alias(\"avg_tip\"),\n",
    ").groupBy('sex', 'smoker').agg(F.mean(avg_column)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_smoker = tips.where(tips[\"smoker\"] == 'Yes')\n",
    "tips_non_smoker = tips.where(tips[\"smoker\"] == 'No')\n",
    "tips_male = tips.where(tips[\"sex\"] == 'Male')\n",
    "tips_female = tips.where(tips[\"sex\"] == 'Female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-------+\n",
      "|customer_tip|total|avg_tip|\n",
      "+------------+-----+-------+\n",
      "|         3.0|38.01|   7.89|\n",
      "|        1.76|11.24|  15.66|\n",
      "|        3.21|20.29|  15.82|\n",
      "|         2.0|13.81|  14.48|\n",
      "|        1.98|11.02|  17.97|\n",
      "+------------+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_column = F.round((col('tip') / col(\"total_bill\")) * 100, 2)\n",
    "\n",
    "tips_smoker.select(\n",
    "    col(\"tip\").alias(\"customer_tip\"),\n",
    "    tips.total_bill.alias(\"total\"),\n",
    "    avg_column.alias(\"avg_tip\"),\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-------+\n",
      "|customer_tip|total|avg_tip|\n",
      "+------------+-----+-------+\n",
      "|        1.01|16.99|   5.94|\n",
      "|        1.66|10.34|  16.05|\n",
      "|         3.5|21.01|  16.66|\n",
      "|        3.31|23.68|  13.98|\n",
      "|        3.61|24.59|  14.68|\n",
      "+------------+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_column = F.round((col('tip') / col(\"total_bill\")) * 100, 2)\n",
    "\n",
    "tips_non_smoker.select(\n",
    "    col(\"tip\").alias(\"customer_tip\"),\n",
    "    tips.total_bill.alias(\"total\"),\n",
    "    avg_column.alias(\"avg_tip\"),\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-------+\n",
      "|customer_tip|total|avg_tip|\n",
      "+------------+-----+-------+\n",
      "|        1.66|10.34|  16.05|\n",
      "|         3.5|21.01|  16.66|\n",
      "|        3.31|23.68|  13.98|\n",
      "|        4.71|25.29|  18.62|\n",
      "|         2.0| 8.77|  22.81|\n",
      "+------------+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_column = F.round((col('tip') / col(\"total_bill\")) * 100, 2)\n",
    "\n",
    "tips_male.select(\n",
    "    col(\"tip\").alias(\"customer_tip\"),\n",
    "    tips.total_bill.alias(\"total\"),\n",
    "    avg_column.alias(\"avg_tip\"),\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-------+\n",
      "|customer_tip|total|avg_tip|\n",
      "+------------+-----+-------+\n",
      "|        1.01|16.99|   5.94|\n",
      "|        3.61|24.59|  14.68|\n",
      "|         5.0|35.26|  14.18|\n",
      "|        3.02|14.83|  20.36|\n",
      "|        1.67|10.33|  16.17|\n",
      "+------------+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_column = F.round((col('tip') / col(\"total_bill\")) * 100, 2)\n",
    "\n",
    "tips_female.select(\n",
    "    col(\"tip\").alias(\"customer_tip\"),\n",
    "    tips.total_bill.alias(\"total\"),\n",
    "    avg_column.alias(\"avg_tip\"),\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the Seattle weather dataset referenced in the lesson to answer the questions below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramirolopez/anaconda3/envs/codeup/lib/python3.11/site-packages/pyspark/sql/pandas/conversion.py:485: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if should_localize and is_datetime64tz_dtype(s.dtype) and s.dt.tz is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "|2012-01-06|          2.5|     4.4|     2.2| 2.2|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather = data.seattle_weather().assign(date=lambda df: df.date.astype(str))\n",
    "weather = spark.createDataFrame(weather)\n",
    "weather.show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert the temperatures to fahrenheit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------------+\n",
      "|Max temp in Celsius|Max temp in Fahrenheit|\n",
      "+-------------------+----------------------+\n",
      "|               12.8|                 55.04|\n",
      "|               10.6|                 51.08|\n",
      "|               11.7|                 53.06|\n",
      "|               12.2|                 53.96|\n",
      "|                8.9|                 48.02|\n",
      "+-------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather = weather.withColumn(\"max_temp_in_fahrenheit\", F.round((F.col(\"temp_max\") * 9/5) + 32, 2))\n",
    "\n",
    "weather.select(\n",
    "    F.col(\"temp_max\").alias(\"Max temp in Celsius\"),\n",
    "    F.col(\"max_temp_in_fahrenheit\").alias(\"Max temp in Fahrenheit\")\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------------+\n",
      "|Min temp in Celsius|Min temp in Fahrenheit|\n",
      "+-------------------+----------------------+\n",
      "|                5.0|                  41.0|\n",
      "|                2.8|                 37.04|\n",
      "|                7.2|                 44.96|\n",
      "|                5.6|                 42.08|\n",
      "|                2.8|                 37.04|\n",
      "+-------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather = weather.withColumn(\"min_temp_in_fahrenheit\", F.round((F.col(\"temp_min\") * 9/5) + 32, 2))\n",
    "\n",
    "weather.select(\n",
    "    F.col(\"temp_min\").alias(\"Min temp in Celsius\"),\n",
    "    F.col(\"min_temp_in_fahrenheit\").alias(\"Min temp in Fahrenheit\")\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which month has the most rain, on average?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+----------------------+----------------------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|max_temp_in_fahrenheit|min_temp_in_fahrenheit|\n",
      "+----------+-------------+--------+--------+----+-------+----------------------+----------------------+\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|                 51.08|                 37.04|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|                 53.06|                 44.96|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|                 53.96|                 42.08|\n",
      "+----------+-------------+--------+--------+----+-------+----------------------+----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_rain = weather.where(weather[\"weather\"] == 'rain')\n",
    "weather_rain.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+----------------------+----------------------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|max_temp_in_fahrenheit|min_temp_in_fahrenheit|\n",
      "+----------+-------------+--------+--------+----+-------+----------------------+----------------------+\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|                 51.08|                 37.04|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|                 53.06|                 44.96|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|                 53.96|                 42.08|\n",
      "+----------+-------------+--------+--------+----+-------+----------------------+----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_rain.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+----------------------+----------------------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|max_temp_in_fahrenheit|min_temp_in_fahrenheit|\n",
      "+----------+-------------+--------+--------+----+-------+----------------------+----------------------+\n",
      "|2012-11-19|         54.1|    13.3|     8.3| 6.0|   rain|                 55.94|                 46.94|\n",
      "+----------+-------------+--------+--------+----+-------+----------------------+----------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_rain.sort(weather_rain.precipitation.desc()).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which year was the windiest?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|wind|\n",
      "+----+\n",
      "| 4.7|\n",
      "| 4.5|\n",
      "+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.select('wind').show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the most frequent type of weather in January?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 248:=================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|weather|count|\n",
      "+-------+-----+\n",
      "|drizzle|   10|\n",
      "|   rain|   35|\n",
      "|    sun|   33|\n",
      "|   snow|    8|\n",
      "|    fog|   38|\n",
      "+-------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "weather_df = weather.withColumn('year', F.year(F.col('date'))).withColumn('month', F.month(F.col('date')))\n",
    "\n",
    "weather_jan = weather_df.where(weather_df[\"month\"] == 1)\n",
    "\n",
    "weather_jan.groupBy(\"weather\").count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the average high and low temperature on sunny days in July in 2013 and 2014?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+----------------------+----------------------+----+-----+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|max_temp_in_fahrenheit|min_temp_in_fahrenheit|year|month|\n",
      "+----------+-------------+--------+--------+----+-------+----------------------+----------------------+----+-----+\n",
      "|2012-01-08|          0.0|    10.0|     2.8| 2.0|    sun|                  50.0|                 37.04|2012|    1|\n",
      "|2012-01-11|          0.0|     6.1|    -1.1| 5.1|    sun|                 42.98|                 30.02|2012|    1|\n",
      "|2012-01-12|          0.0|     6.1|    -1.7| 1.9|    sun|                 42.98|                 28.94|2012|    1|\n",
      "+----------+-------------+--------+--------+----+-------+----------------------+----------------------+----+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_sunny = weather_df.where(weather[\"weather\"] == 'sun').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'filter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/ramirolopez/codeup-data-science/spark-exercises/spark101.ipynb Cell 51\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ramirolopez/codeup-data-science/spark-exercises/spark101.ipynb#Y132sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m weather_sunny\u001b[39m.\u001b[39;49mfilter(weather_sunny[\u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m2013\u001b[39m)\u001b[39m.\u001b[39mshow()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'filter'"
     ]
    }
   ],
   "source": [
    "weather_sunny.filter(weather_sunny['year'] == 2013).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What percentage of days were rainy in Q3 of 2015?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+----------------------+----------------------+----+-----+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|max_temp_in_fahrenheit|min_temp_in_fahrenheit|year|month|\n",
      "+----------+-------------+--------+--------+----+-------+----------------------+----------------------+----+-----+\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|                 51.08|                 37.04|2012|    1|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|                 53.06|                 44.96|2012|    1|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|                 53.96|                 42.08|2012|    1|\n",
      "+----------+-------------+--------+--------+----+-------+----------------------+----------------------+----+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_rainy = weather_df.where(weather_df[\"weather\"] == 'rain').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'filter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/ramirolopez/codeup-data-science/spark-exercises/spark101.ipynb Cell 54\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ramirolopez/codeup-data-science/spark-exercises/spark101.ipynb#Y144sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m rainy_year_2012 \u001b[39m=\u001b[39m weather_rainy\u001b[39m.\u001b[39;49mfilter(weather_rainy[\u001b[39m\"\u001b[39m\u001b[39myear\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m2015\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'filter'"
     ]
    }
   ],
   "source": [
    "rainy_year_2012 = weather_rainy.filter(weather_rainy[\"year\"] == 2015)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 126:=======>                                                 (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|2012|  366|\n",
      "|2013|  365|\n",
      "|2014|  365|\n",
      "|2015|  365|\n",
      "+----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "value_counts = weather_df.groupBy(\"year\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_2012 = weather_df.filter(weather_df[\"year\"] == 2012)\n",
    "year_2013 = weather_df.filter(weather_df[\"year\"] == 2013)\n",
    "year_2014 = weather_df.filter(weather_df[\"year\"] == 2014)\n",
    "year_2015 = weather_df.filter(weather_df[\"year\"] == 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent of 2012 -> 0.52\n",
      "percent of 2013 -> 0.58\n",
      "percent of 2014 -> 0.59\n",
      "percent of 2015 -> 0.61\n"
     ]
    }
   ],
   "source": [
    "count_2012 = year_2012.where(year_2012['precipitation'] == 0).count()\n",
    "count_2013 = year_2013.where(year_2013['precipitation'] == 0).count()\n",
    "count_2014 = year_2014.where(year_2014['precipitation'] == 0).count()\n",
    "count_2015 = year_2015.where(year_2015['precipitation'] == 0).count()\n",
    "\n",
    "percent_2012 = round(count_2012 / year_2012.count(), 2)\n",
    "percent_2013 = round(count_2013 / year_2013.count(), 2)\n",
    "percent_2014 = round(count_2014 / year_2014.count(), 2)\n",
    "percent_2015 = round(count_2015 / year_2015.count(), 2)\n",
    "\n",
    "print(f'percent of 2012 -> {percent_2012}')\n",
    "print(f'percent of 2013 -> {percent_2013}')\n",
    "print(f'percent of 2014 -> {percent_2014}')\n",
    "print(f'percent of 2015 -> {percent_2015}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
